<!DOCTYPE html>
<!--
    Type on Strap jekyll theme v2.4.7
    Theme free for personal and commercial use under the MIT license
    https://github.com/sylhare/Type-on-Strap/blob/master/LICENSE
-->
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=0.5, maximum-scale=5">
        
    <!-- Theme Mode-->
    
    
    <script>
        const strSystem = "System";
        const strLight = "Light";
        const strDark = "Dark";
        const strSwitchTo = "Switch to";
        const strOpenMenu = "Open menu";
        const strCloseMenu = "Close menu";
        const isAutoTheme = true;
        if (isAutoTheme) {
            var savedPreference = sessionStorage.getItem('theme');
            var preferredTheme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
            if (savedPreference) {
                document.documentElement.setAttribute('data-theme-preference', savedPreference);
                document.documentElement.setAttribute('data-theme', savedPreference === 'system' ? preferredTheme : savedPreference);
            } else {
                document.documentElement.setAttribute('data-theme-preference', 'system');
                document.documentElement.setAttribute('data-theme', preferredTheme);
            }
        } else {
            document.documentElement.setAttribute('data-theme', "auto");
        }
    </script>

    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer src="/assets/js/main.min.js"></script>

    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">
    
    <!-- Font Awesome 6.7.0 -->
    <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.0/css/all.min.css" crossorigin="anonymous" referrerpolicy="no-referrer">

    <!--Favicon-->
    <link rel="shortcut icon" href="/assets/img/logos/avatar.svg" type="image/x-icon">

    

    <!-- KaTeX 0.13.9 -->
    
    <script defer src="/assets/js/vendor/katex.min.js"></script>
    <script defer src="/assets/js/vendor/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
    

    <!-- Mermaid 10.6.1 -->
    
    <script defer src="/assets/js/vendor/mermaid.min.js" onload="mermaid.initialize({
      startOnLoad:true,
      theme: 'true',
    });"></script>
    

    <!-- Simple Jekyll Search 1.10.0 (only load on search page) -->
    

    <!-- Google Analytics / Cookie Consent -->
    <script>
      const cookieName = 'cookie-notice-dismissed-https://everettyou.github.io';
      const isCookieConsent = '';
      const analyticsName = 'G-MTBKDXJMFH';
      const analyticsNameGA4 = '';
    </script>

    
    
        <!-- Global site tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-MTBKDXJMFH"></script>
    

    <!-- seo tags -->
    <meta property="og:image" content="https://everettyou.github.io/assets/img/figures/cover.png">
    
    <meta property="og:type" content="website" />
    
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>A Tale of Two Decays: Why Your AI Assistant Loses “Focus” on Long Tasks | You Group @ UCSD</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="A Tale of Two Decays: Why Your AI Assistant Loses “Focus” on Long Tasks" />
<meta name="author" content="Gemini 3" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We’ve all had those moments with ChatGPT or Gemini. One minute, it’s writing a brilliant sonnet, and the next, it fails to multiply two large numbers or loses the plot halfway through a complex logical deduction. It begs the question: What is actually happening inside the “mind” of an LLM? Is it a reasoning agent, capable of complex thought? Or is it, as some critics suggest, just a “stochastic parrot”—a mimic that predicts the next word without understanding the whole picture?" />
<meta property="og:description" content="We’ve all had those moments with ChatGPT or Gemini. One minute, it’s writing a brilliant sonnet, and the next, it fails to multiply two large numbers or loses the plot halfway through a complex logical deduction. It begs the question: What is actually happening inside the “mind” of an LLM? Is it a reasoning agent, capable of complex thought? Or is it, as some critics suggest, just a “stochastic parrot”—a mimic that predicts the next word without understanding the whole picture?" />
<link rel="canonical" href="https://everettyou.github.io/2025/11/24/LLMFocus.html" />
<meta property="og:url" content="https://everettyou.github.io/2025/11/24/LLMFocus.html" />
<meta property="og:site_name" content="You Group @ UCSD" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-11-24T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="A Tale of Two Decays: Why Your AI Assistant Loses “Focus” on Long Tasks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Gemini 3","url":"https://gemini.google.com/"},"dateModified":"2025-11-24T00:00:00+00:00","datePublished":"2025-11-24T00:00:00+00:00","description":"We’ve all had those moments with ChatGPT or Gemini. One minute, it’s writing a brilliant sonnet, and the next, it fails to multiply two large numbers or loses the plot halfway through a complex logical deduction. It begs the question: What is actually happening inside the “mind” of an LLM? Is it a reasoning agent, capable of complex thought? Or is it, as some critics suggest, just a “stochastic parrot”—a mimic that predicts the next word without understanding the whole picture?","headline":"A Tale of Two Decays: Why Your AI Assistant Loses “Focus” on Long Tasks","mainEntityOfPage":{"@type":"WebPage","@id":"https://everettyou.github.io/2025/11/24/LLMFocus.html"},"url":"https://everettyou.github.io/2025/11/24/LLMFocus.html"}</script>
<!-- End Jekyll SEO tag -->


    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="You Group @ UCSD" href="https://everettyou.github.io/feed.xml"/>
    <link type="application/atom+xml" rel="alternate" href="https://everettyou.github.io/feed.xml" title="You Group @ UCSD" />

    <!-- Twitter Cards -->
    <meta name="twitter:title" content="A Tale of Two Decays: Why Your AI Assistant Loses "Focus" on Long Tasks">
    <meta name="twitter:description" content="We’ve all had those moments with ChatGPT or Gemini. One minute, it’s writing a brilliant sonnet, and the next, it fails to multiply two large numbers or lose...">
    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:image" content="https://everettyou.github.io/assets/img/figures/cover.png">
    <meta name="twitter:image:alt" content="A Tale of Two Decays: Why Your AI Assistant Loses "Focus" on Long Tasks">
</head>
  <body>
    <header class="site-header">

    <!-- Logo and title -->
    <div class="branding">
        
        <a href="/">
            <img alt="logo img" class="avatar" src="/assets/img/logos/avatar.svg" loading="lazy"/>
        </a>
        
        <a class="site-title" aria-label="You Group @ UCSD" href="/">
        You Group @ UCSD
        </a>
    </div>

    <!-- Toggle menu button -->
    
    
    
    
    <a id="pull" class="toggle" href="#">
      <i class="menu-icon-open fa-solid fa-bars fa-lg" title="Open menu" aria-label="Open menu"></i>
      <i class="menu-icon-close fa-solid fa-x fa-lg" title="Close menu" aria-label="Close menu"></i>
    </a>

    <!-- Navigation menu -->
    <nav class="clear">
    <ul class="hide">
        

        <!-- First pass: render non-icon pages -->
        
            
                
                    <li class="separator"> | </li>
                    <li>
                        <a class="clear" aria-label="Research" title="Research" href="/research/">
                            Research
                        </a>
                    </li>
                
            
            
        
            
                
                    <li class="separator"> | </li>
                    <li>
                        <a class="clear" aria-label="Teaching" title="Teaching" href="/teaching/">
                            Teaching
                        </a>
                    </li>
                
            
            
        
            
                
                    <li class="separator"> | </li>
                    <li>
                        <a class="clear" aria-label="People" title="People" href="/people/">
                            People
                        </a>
                    </li>
                
            
            
        
            
            
        
            
                
                    <li class="separator"> | </li>
                    <li>
                        <a class="clear" aria-label="Publication" title="Publication" href="/publications/">
                            Publication
                        </a>
                    </li>
                
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
                
            
            
        
            
            
        
            
                
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        
            
            
        

        <!-- Second pass: render icon pages and theme-toggle grouped together in a single li -->
        <li class="separator"> | </li>
        <li class="icon-menu-group">
            
            
                
                    
                
                
            
                
                    
                
                
            
                
                    
                
                
            
                
                
            
                
                    
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                    
                        <a class="clear icon-menu-item" aria-label="Search" title="Search" href="/search.html">
                            <i class="fa-solid fa-search" aria-hidden="true"></i>
                        </a>
                    
                
                
            
                
                
            
                
                    
                        <a class="clear icon-menu-item" aria-label="Tags" title="Tags" href="/tags/">
                            <i class="fa-solid fa-tags" aria-hidden="true"></i>
                        </a>
                    
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
                
                
            
            
            
            
            
            
            
            
            <a id="theme-toggle" class="clear icon-menu-item" title="Switch to System" aria-label="Switch to System" onclick="themeToggle()"></a>
            
        </li>
    </ul>

    </nav>
</header>
    <div class="content">
      <article >
  <header id="main" style="">
    <div class="title-padder">
      
      <h2 id="A+Tale+of+Two+Decays%3A+Why+Your+AI+Assistant+Loses+%22Focus%22+on+Long+Tasks" class="title"><p>A Tale of Two Decays: Why Your AI Assistant Loses “Focus” on Long Tasks</p>
</h2>
      






<div class="post-info"><a href="https://gemini.google.com/" target="_blank">
      <img alt="Author's avatar" src="/assets/img/logos/gemini.svg">
    
    <p class="meta">
      Gemini 3 - 
      
        
        
        
        
        
          November 24, 2025
        
      
    </p></a></div>

      
    </div>
  </header>

  <section class="post-content">
  
      <p>We’ve all had those moments with ChatGPT or Gemini. One minute, it’s writing a brilliant sonnet, and the next, it fails to multiply two large numbers or loses the plot halfway through a complex logical deduction. It begs the question: <strong>What is actually happening inside the “mind” of an LLM?</strong> Is it a reasoning agent, capable of complex thought? Or is it, as some critics suggest, just a “stochastic parrot”—a mimic that predicts the next word without understanding the whole picture?</p>

<p>In our latest paper, “<em>How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic Prediction Tasks</em>” (<a href="https://arxiv.org/abs/2511.00763" target="_blank">arXiv:2511.00763</a>), our team at <em>EdenCode</em> and <em>Path Integral Technology</em>, together with researchers from <em>Harvard University</em> and <em>UC Davis</em>, decided to stop guessing and start measuring. We took a physicist’s approach to studying Artificial Intelligence, treating the LLM not as a magical black box, but as a complex physical system. Here is what we found.</p>

<h3 id="system-1-vs-system-2-parrot-or-scientist">System 1 vs. System 2: Parrot or Scientist?</h3>

<p>To understand why LLMs fail, we first need to look at human cognition. The Nobel laureate Daniel Kahneman described two distinct modes of thinking:</p>

<p><img src="/assets/img/figures/LLM-system1or2.png" alt="What is LLM's operating mode? A mimicking parrot or a reasoning agent?" /></p>

<ul>
  <li><strong>System 1 (Intuition)</strong> is fast, automatic, and subconscious—think of a <strong>parrot mimicking speech</strong>, responding instantly based on patterns it has heard before, without pausing to understand the underlying logic.</li>
  <li><strong>System 2 (Reasoning)</strong> is slow, deliberate, and conscious—think of a <strong>scientist solving a complex problem</strong>, who must plan, calculate, and verify each step carefully.</li>
</ul>

<p>Current LLMs are masters of <strong>System 1</strong>. They generate the next word immediately based on statistical likelihood. They don’t naturally “stop and think.” But what happens when we force a System 1 thinker to do a System 2 task—something that requires maintaining a coherent chain of logic over a long sequence?</p>

<h3 id="the-experiment-why-accuracy-matters-in-science">The Experiment: Why “Accuracy” Matters in Science</h3>

<p>Evaluating an AI’s performance is usually tricky. If you ask an LLM to “write a poem about the ocean,” there is no single correct answer. You can’t really calculate an “accuracy rate” for poetry or conversation. However, the game changes when we apply <strong>AI for Science</strong>.</p>

<p>In science and math, problems often admit <strong>unique, correct solutions</strong>. If we ask for the sum of two integers, the result is exact. If we ask for the product of quantum operators, there is no room for “creative interpretation.” This scientific context allows us to define a rigorous metric: <strong>SAR (Sequence Accuracy Rate)</strong>. This measures the probability that the <em>entire</em> output sequence is 100% correct. Using this, we tested models on integer addition, cyclic letter replacement, and quantum physics math.</p>

<h3 id="the-accuracy-cliff-defining-the-effective-focus-range">The “Accuracy Cliff”: Defining the Effective Focus Range</h3>

<p>If an LLM were simply making random, independent mistakes at each step (like rolling a die), its accuracy would drop off steadily following an exponential decay as the task got longer. But that’s not what we found. Instead, we observed a phenomenon we call the <strong>Accuracy Cliff</strong>.</p>

<p><img src="/assets/img/figures/tale-of-two-decays.png" alt="The Mystery of LLM Focus: A Tale of Two Decays" /></p>

<p>The models perform perfectly for a while, and then—suddenly—reliability collapses. It’s not a gentle decline; it’s a crash. This threshold defines the model’s <strong>Effective Focus Range</strong>. Within this range, the model is reliable. Beyond it, it hallucinates. Mathematically, we found the errors follow a <strong>double-exponential decay</strong> law. In plain English? <strong>The errors are contagious.</strong> One small mistake doesn’t just stay isolated; it propagates through the model’s attention mechanism, triggering a cascade of failures.</p>

<h3 id="the-physics-of-losing-focus">The Physics of “Losing Focus”</h3>

<p>As a physicist, this curve looks familiar. It resembles <strong>phase transitions</strong> in magnetic materials (specifically, spin glasses). LLMs are built on the “Attention Mechanism”. Every word attends to every other word. While this allows the model to understand context, it also means that <strong>noise propagates globally</strong>.</p>

<p>Think of it like a room full of people trying to pass a complex message: if they whisper primarily to their neighbors (independent errors), the message degrades gradually. But in an LLM, everyone is shouting at everyone else (all-to-all attention). If one person gets confused, that “noise” spreads to everyone else instantly via the dense connections. This is “internal interference.”</p>

<p>To understand this crash quantitatively, we modeled the LLM using the <strong>Sherrington-Kirkpatrick Spin Glass</strong> model, treating every generated token as a tiny magnet (an “Ising spin”)—pointing “up” if correct and “down” if hallucinating. In this physical system, reliability is a tug-of-war between stability and noise. The force keeping the model on track grows linearly with the sequence length (\(N\)), but the chaotic interference—fueled by the model’s all-to-all Attention Mechanism—explodes much faster, scaling as the square of the length (\(N^2\)). For short tasks, stability wins; but as the task lengthens, the quadratic noise inevitably overpowers the linear stability, triggering a sudden “phase transition.” The “spins” don’t just flip randomly one by one; they flip in a correlated burst, causing the entire reasoning chain to collapse in the catastrophic collective error we observe as the Accuracy Cliff.</p>

<h3 id="the-solution-engineering-fault-tolerance">The Solution: Engineering Fault Tolerance</h3>

<p>So, is there hope for long-context reasoning? Yes. Once we understood the physics of the failure (correlated error accumulation), the engineering solution became clear: <strong>Break the loops.</strong></p>

<p>We applied a <strong>Divide-and-Conquer</strong> strategy. Instead of asking the model to solve a massive problem in one breath, we chop the task into smaller, manageable sub-tasks that fit well within the model’s Effective Focus Range: solve Part A, solve Part B, then combine them. By effectively “resetting” the model’s context between steps, we stop the errors from snowballing. Our data shows that this simple algorithmic change pushes the “Accuracy Cliff” significantly further out, turning a hallucinating model into a reliable reasoning agent.</p>

<h3 id="the-future-ai-needs-error-correction">The Future: AI Needs Error Correction</h3>

<p><img src="/assets/img/figures/physics-of-LLM.png" alt="Physics of LLMs: From Error Mechanism to Fault-Tolerance" /></p>

<p>In quantum computing, we accept that “qubits are noisy,” so we build <strong>Quantum Error Correction</strong> to make them reliable. Our takeaway message is that <strong>Classical AI needs error correction too</strong>. We cannot just build bigger models and hope they magically become perfectly logical. We need to design architectures that acknowledge the intrinsic noise, manage the interference, and engineer fault tolerance into the system. If we want AI that can reason like a scientist (System 2) rather than just mimic like a parrot (System 1), we have to treat it like a complex physical system—and fix the physics.</p>

<p>(<em>Written by Google Gemini 3</em>)</p>

<hr />

<p><em>You can read our full paper on <a href="https://arxiv.org/abs/2511.00763" target="_blank">arXiv:2511.00763</a>.</em></p>


    
  </section>

  <!-- Social media shares -->
  



<div class="share-buttons">
    <ul class="share-buttons">
        <li class="meta">Share</li>
        
        <li>
            <a href="https://www.facebook.com/sharer/sharer.php?u=https://everettyou.github.io/2025/11/24/LLMFocus.html" target="_blank"
               title="Share on Facebook">
                <i class="fa-brands fa-facebook-square fa-2x" aria-hidden="true"></i>
                <span class="sr-only">Share on Facebook</span>
            </a>
        </li>
             
        <li>
            <a href="https://www.reddit.com/submit?url=https://everettyou.github.io/2025/11/24/LLMFocus.html&title=A+Tale+of+Two+Decays%3A+Why+Your+AI+Assistant+Loses+%22Focus%22+on+Long+Tasks%20%7C%20You+Group+%40+UCSD"
               target="_blank" title="Share on Reddit">
                <i class="fa-brands fa-reddit-square fa-2x" aria-hidden="true"></i>
                <span class="sr-only">Share on Reddit</span>
            </a>
        </li>
         
        <li>
            <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://everettyou.github.io/2025/11/24/LLMFocus.html&title=A+Tale+of+Two+Decays%3A+Why+Your+AI+Assistant+Loses+%22Focus%22+on+Long+Tasks%20%7C%20You+Group+%40+UCSD&summary=&source=https://everettyou.github.io/2025/11/24/LLMFocus.html"
               target="_blank" title="Share on LinkedIn">
                <i class="fa-brands fa-linkedin fa-2x" aria-hidden="true"></i>
                <span class="sr-only">Share on LinkedIn</span>
            </a>
        </li>
          
    </ul>
</div>




   <!-- Tag list -->
  
  


  <div class="tag-list">
    <ul>
      
        <li class="meta">Tags</li>
      

      
        <li><a class="button" href="/tags#AI">
          <p><i class="fa-solid fa-tag fa-fw fa-sm"></i> AI</p>
        </a></li>
      
        <li><a class="button" href="/tags#LLM">
          <p><i class="fa-solid fa-tag fa-fw fa-sm"></i> LLM</p>
        </a></li>
      
        <li><a class="button" href="/tags#Machine+Learning">
          <p><i class="fa-solid fa-tag fa-fw fa-sm"></i> Machine Learning</p>
        </a></li>
      
        <li><a class="button" href="/tags#Physics">
          <p><i class="fa-solid fa-tag fa-fw fa-sm"></i> Physics</p>
        </a></li>
      
    </ul>
  </div>


</article>

<!-- Post navigation -->



<div id="post-nav">
    

    
    <div id="next-post">
        <a alt="Can GPT Speak the Quantum Language?" href="/2024/11/07/ShadowGPT.html">
            <p>Next post</p>
            Can GPT Speak the Quantum Language?
        </a>
    </div>
    
</div>



<!--Utterances-->


<!-- Cusdis -->


<!-- Disqus -->


<!-- To change color of links in the page -->
<style>
  header#main {
      background-size: cover;
      background-repeat: no-repeat;
      background-position: center;
  }

  

  
</style>
    </div>
    <footer class="site-footer">
    <p class="text">
        
    </p>
    <p>
        <a href="https://ucsd.edu/" target="_blank">UCSD</a> | 
        <a href="https://physics.ucsd.edu/" target="_blank">Department of Physics</a> | 
        <a href="https://physics.ucsd.edu/research/condensed-matter-physics" target="_blank">Condensed Matter Group</a>
    </p>
    <p>Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> 
        with <a href="https://github.com/sylhare/Type-on-Strap" target="_blank">Type on Strap</a> | 
        <a href="/privacy.html">Privacy Statement</a> 
    </p>
    <div class="footer-icons">
        <ul>
        <!-- Social icons from Font Awesome, if enabled -->
        


<li>
    <a feed.xml href="/feed.xml"
       title="Follow RSS feed"
       target="_blank">
        <span class="fa-stack fa-lg">
            <i class="fa-solid fa-circle fa-stack-2x"></i>
            <i class="fa-solid fa-rss fa-stack-1x fa-inverse"></i>
        </span>
    </a>
</li>



  
  
      
    
    
    
    
    
    <li>
      <a href="mailto:yzyou@physics.ucsd.edu"
         title="Contact via E-mail"
         target="_blank"
         rel="me">
        <span class="fa-stack fa-lg">
          <i class="fa-solid fa-circle fa-stack-2x"></i>
          <i class="fa-solid fa-envelope fa-stack-1x fa-inverse"></i>
        </span>
      </a>
    </li>
  

  
  
      
    
    
    
    
    
    <li>
      <a href="https://scholar.google.com/citations?hl=en&user=PLFbeHMAAAAJ"
         title="Follow on Google Scholar"
         target="_blank"
         rel="me">
        <span class="fa-stack fa-lg">
          <i class="fa-solid fa-circle fa-stack-2x"></i>
          <i class="fa-solid fa-user-graduate fa-stack-1x fa-inverse"></i>
        </span>
      </a>
    </li>
  

  
  
      
    
    
    
    
    
    <li>
      <a href="https://orcid.org/0000-0003-4080-5340"
         title="Follow on ORCiD"
         target="_blank"
         rel="me">
        <span class="fa-stack fa-lg">
          <i class="fa-solid fa-circle fa-stack-2x"></i>
          <i class="fa-brands fa-orcid fa-stack-1x fa-inverse"></i>
        </span>
      </a>
    </li>
  

  
  
      
    
    
    
    
    
    <li>
      <a href="https://github.com/EverettYou"
         title="Follow on GitHub"
         target="_blank"
         rel="me">
        <span class="fa-stack fa-lg">
          <i class="fa-solid fa-circle fa-stack-2x"></i>
          <i class="fa-brands fa-github fa-stack-1x fa-inverse"></i>
        </span>
      </a>
    </li>
  

  
  
      
    
    
    
    
    
    <li>
      <a href="https://www.linkedin.com/in/yi-zhuang-you-1703a1272"
         title="Follow on LinkedIn"
         target="_blank"
         rel="me">
        <span class="fa-stack fa-lg">
          <i class="fa-solid fa-circle fa-stack-2x"></i>
          <i class="fa-brands fa-linkedin fa-stack-1x fa-inverse"></i>
        </span>
      </a>
    </li>
  



        </ul>
    </div>
</footer>
  </body>
</html>